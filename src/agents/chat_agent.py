import asyncio
import sys
from pathlib import Path
from typing import Dict, Optional

from langchain_core.messages import HumanMessage
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableLambda
from langchain_openai import ChatOpenAI
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import StateGraph, MessagesState, START, END
from configs.settings import *
from src.agents.base import BaseAgent
# è®¾ç½®é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent.parent.resolve()
sys.path.insert(0, str(project_root))

# æœ¬åœ°æ¨¡å—å¯¼å…¥
from rag import GraphRAG
from api.websearch.websearcher import *

base_path = Path(__file__).parent.parent.parent  # Smart-Assistant æ ¹ç›®å½•
artifacts_path = base_path / "rag" / "artifacts"

# è¾…åŠ©ç±»
class AgentState(MessagesState):
    next: str


class PokemonKGChatAgent(BaseAgent):
    """å®å¯æ¢¦çŸ¥è¯†å›¾è°±èŠå¤©ä»£ç†"""

    def __init__(self, openai_base_url: str = MODEL_API_BASE,
            openai_api_key: str = MODEL_API_KEY,
            model_name:str =MODEL_NAME
                 ):
        self.model_name=model_name
        self.openai_base_url = openai_base_url
        self.openai_api_key = openai_api_key
        self._init_components()
        self._build_graph()
    def _init_components(self):
        """åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶"""
        # åˆå§‹åŒ–LLM
        self.llm = ChatOpenAI( model=self.model_name,
            base_url=self.openai_base_url,
            api_key=self.openai_api_key)
        from src.agents.kg_agent import KGQueryAgent
        self.kgsql_agent = KGQueryAgent(llm=self.llm)
        # åˆå§‹åŒ–çŸ¥è¯†å›¾è°±æŸ¥è¯¢ä»£ç† 1


        # åˆå§‹åŒ–å›¾RAG 1
        self.graph_rag = GraphRAG(
            artifacts_path=str(artifacts_path),
            community_level=0
        )

        self.searcher = LiteBaseSearcher()

        # æ·»åŠ å…¼å®¹æ–¹æ³•ï¼Œé¿å… AttributeError
        async def fake_search_and_generate(query: str) -> str:
            return f"ï¼ˆæ¨¡æ‹Ÿè”ç½‘æœç´¢ç»“æœï¼Œæ— å®é™…è”ç½‘ï¼‰Query: {query}"

        self.searcher.search_and_generate = fake_search_and_generate

    def _build_graph(self):
        """æ„å»ºLangGraphçŠ¶æ€å›¾"""
        # å®šä¹‰èŠ‚ç‚¹
        builder = StateGraph(AgentState)

        # æ·»åŠ èŠ‚ç‚¹
        builder.add_node("supervisor", self._supervisor)
        builder.add_node("chat", self._chat)
        builder.add_node("kg_sqler", self._kgsql_node)
        builder.add_node("graph_rager", self._graph_rager)
        builder.add_node("web_searcher", RunnableLambda(self._web_searcher))

        # å®šä¹‰æˆå‘˜åˆ—è¡¨
        members = ["chat", "kg_sqler", "graph_rager", "web_searcher"]

        # æ·»åŠ è¾¹
        for member in members:
            builder.add_edge(member, "supervisor")

        # æ·»åŠ æ¡ä»¶è¾¹
        builder.add_conditional_edges("supervisor", lambda state: state["next"])
        builder.add_edge(START, "supervisor")

        # ç¼–è¯‘å›¾
        self.graph = builder.compile(checkpointer=MemorySaver())

    # èŠ‚ç‚¹å‡½æ•°å®šä¹‰
    def _chat(self, state: AgentState):
        """è‡ªç„¶è¯­è¨€èŠå¤©èŠ‚ç‚¹"""
        messages = state["messages"]
        model_response = self.llm.invoke(messages)
        return {"messages": model_response}

    def _kgsql_node(self, state: AgentState):
        """çŸ¥è¯†å›¾è°±æŸ¥è¯¢èŠ‚ç‚¹"""
        result = self.kgsql_agent.agent.invoke(state)
        return {
            "messages": [
                HumanMessage(content=result["messages"][-1].content, name="kg_sqler")
            ]
        }

    def _graph_rager(self, state: AgentState):
        """å›¾RAGæŸ¥è¯¢èŠ‚ç‚¹"""
        messages = state["messages"]
        response = self.graph_rag.query(messages)
        return {"messages": [HumanMessage(content=response.content, name="graph_rager")]}

    async def _web_searcher(self, state: AgentState):
        """ç½‘ç»œæœç´¢èŠ‚ç‚¹"""
        logger.info("ğŸ“¡ å·²è°ƒç”¨ web_searcher èŠ‚ç‚¹")
        messages = state["messages"]
        response = await self.searcher.search_and_generate(messages[0].content)
        return {"messages": [HumanMessage(content=response, name="web_searcher")]}

    def _supervisor(self, state: AgentState):
        """ç›‘ç£å‘˜èŠ‚ç‚¹"""
        system_prompt = (
            "ä½ è¢«æŒ‡å®šä¸ºå¯¹è¯ç›‘ç£å‘˜ï¼Œè´Ÿè´£åè°ƒä»¥ä¸‹å·¥ä½œæ¨¡å—çš„åä½œï¼š{members}\n\n"
            "å„æ¨¡å—èŒèƒ½åˆ’åˆ†ï¼š\n"
            "- chatï¼šè‡ªç„¶è¯­è¨€äº¤äº’æ¨¡å—\n"
            "  â€¢ ç›´æ¥å¤„ç†ç”¨æˆ·è¾“å…¥çš„è‡ªç„¶è¯­è¨€å“åº”\n"
            "- kg_sqlerï¼šå®å¯æ¢¦çŸ¥è¯†å›¾è°±æŸ¥è¯¢æ¨¡å—\n"
            "  â€¢ å±æ€§æ•°æ®ï¼ˆç§æ—å€¼/è¿›åŒ–é“¾/ç‰¹æ€§ï¼‰\n"
            "  â€¢ è§’è‰²å…³ç³»ï¼ˆè®­ç»ƒå¸ˆ/åŠ²æ•Œ/å›¢é˜Ÿï¼‰\n"
            "  â€¢ åœ°åŸŸæƒ…æŠ¥ï¼ˆåœ°ç‚¹/é“é¦†/æ –æ¯åœ°ï¼‰\n"
            "- graph_ragerï¼šå®å¯æ¢¦ç›¸å…³çŸ¥è¯†åº“\n"
            "  â€¢ äººç‰©ä»‹ç»ï¼ˆå¦‚äººç‰©äº‹è¿¹ç­‰ï¼‰\n"
            "  â€¢ ç¤¾ç¾¤å‘ç°ï¼ˆå¦‚é“é¦†æ´¾ç³»è¯†åˆ«ï¼‰\n"
            "  â€¢ è·¯å¾„åˆ†æï¼ˆè§’è‰²å…³è”è·¯å¾„è¿½è¸ªï¼‰\n"
            "  â€¢ æ—¶åºå…³è”ï¼ˆèµ›äº‹å‚ä¸æ—¶é—´è½´åˆ†æï¼‰\n\n"
            "- web_searcherï¼šå®æ—¶è”ç½‘æœç´¢æ¨¡å—\n"
            "  â€¢ å½“é—®é¢˜æ¶‰åŠæœ€æ–°èµ„è®¯ã€æ–°é—»æˆ–æ—¶æ•ˆæ€§å†…å®¹æ—¶ä½¿ç”¨\n"
            "  â€¢ å½“å…¶ä»–çŸ¥è¯†åº“æ— æ³•æä¾›å‡†ç¡®ç­”æ¡ˆæ—¶ä½¿ç”¨\n"
            "  â€¢ å¯è·å–å®˜æ–¹å…¬å‘Šã€èµ›äº‹ç»“æœç­‰å®æ—¶ä¿¡æ¯\n"
            "  â€¢ èƒ½æŸ¥è¯¢å®å¯æ¢¦ç›¸å…³ç¤¾åŒºè®¨è®ºå’Œç©å®¶åé¦ˆ\n"
            "  â€¢ å¯éªŒè¯å…¶ä»–æ¨¡å—æä¾›ä¿¡æ¯çš„æ—¶æ•ˆæ€§å’Œå‡†ç¡®æ€§\n\n"
            "æ¨¡å—è°ƒç”¨åŸåˆ™ï¼š\n"
            "1. ä¼˜å…ˆä½¿ç”¨æœ¬åœ°çŸ¥è¯†åº“(kg_sqler/graph_rager)å›ç­”å·²çŸ¥çš„å®å¯æ¢¦çŸ¥è¯†\n"
            "2. å½“é—®é¢˜æ¶‰åŠå®æ—¶ä¿¡æ¯æˆ–æœ¬åœ°çŸ¥è¯†ä¸è¶³æ—¶ï¼Œè°ƒç”¨web_searcher\n"
            "3. è¯·æ ¹æ®ç”¨æˆ·è¯·æ±‚æŒ‡å®šä¸‹ä¸€ä¸ªæ‰§è¡Œæ¨¡å—ã€‚"
            "4. æ¯ä¸ªæ¨¡å—æ‰§è¡Œåå°†è¿”å›ä»»åŠ¡ç»“æœåŠçŠ¶æ€ã€‚\n"
            "æ‰§è¡Œæµç¨‹è§„èŒƒï¼š\n"
            "1. chatæ¨¡å—æœ€å¤šèƒ½è°ƒç”¨ä¸€æ¬¡\n"
            "2. å¯ä»¥é“¾å¼è°ƒç”¨å¤šä¸ªæ¨¡å—ï¼ˆå¦‚å…ˆç”¨kg_sqleræŸ¥è¯¢ï¼Œå†ç”¨web_searcheréªŒè¯ï¼‰\n"
            "3. ä½ å¯ä»¥ä¸æ–­è°ƒç”¨ä¸Šè¿°çš„æ¨¡å—ï¼Œå½“æŸä¸ªæ¨¡å—çš„ç»“æœä¸è¶³ä»¥å›ç­”ç”¨æˆ·çš„é—®é¢˜æ—¶ï¼ˆå¦‚æœªæŸ¥è¯¢åˆ°ç›¸å…³ç»“æœï¼‰ï¼Œä½ å¯ä»¥ç»§ç»­è°ƒç”¨å…¶ä»–æ¨¡å—ï¼Œç›´åˆ°ç”¨æˆ·é—®é¢˜å¾—åˆ°å›ç­”ã€‚"
            "4. å½“ä½ ä»»åŠ¡å®Œæˆæ—¶ï¼Œæ‰èƒ½è¿”å›FINISHç»ˆæ­¢ç¬¦"
        )

        prompt = ChatPromptTemplate.from_template("""
        è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹JSONæ ¼å¼å›å¤ï¼ŒåªåŒ…å«nextå­—æ®µ:
        {{
            "next": "FINISH"
        }}
        è¾“å…¥ï¼š{input}
        """)

        messages = [{"role": "system", "content": system_prompt}] + state["messages"]
        chain = prompt | self.llm | JsonOutputParser()
        response = chain.invoke({"input": messages})

        next_ = response["next"]
        return {"next": END if next_ == "FINISH" else next_}

    # å…¬å…±æ¥å£
    async def query(
        self,
        question: str,
        meta: Optional[Dict[str, Any]] = None,
        history: Optional[List[Dict[str, Any]]] = None
    ):
        input_message = {"messages": [HumanMessage(content=question)]}
        config = {"configurable": {"thread_id": "0"}}

        # # å¦‚æœä½ æƒ³ç”¨ meta ä¸­çš„ db_id äº¤ç»™ graph_rag æˆ– kgsql_agent
        # db_id = meta.get("db_id") if meta else None
        # if db_id:
        #     self.graph_rag.set_db_id(db_id)
        #     self.kgsql_agent.set_db_id(db_id)

        chunks = []
        async for chunk in self.graph.astream(input_message, config, stream_mode="values"):
            chunks.append(chunk["messages"][-1])

        yield chunks[-1].content if chunks else None
    def get_info(self):
        return {
            "name": "chat_agent",
            "description": "å®å¯æ¢¦å›¾è°±æ™ºèƒ½ä½“",
            "requirements": ["NEO4J_URI"],
            "all_tools": ["graph_query", "retrieval"]
        }


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    async def main():
        # åˆå§‹åŒ–ä»£ç†
        agent = PokemonKGChatAgent()
        # ç¤ºä¾‹æŸ¥è¯¢
        question = "æ‹¥æœ‰çš®å¡ä¸˜çš„è§’è‰²ä¸­ï¼Œæœ‰å“ªäº›æ˜¯å°åˆšçš„ä¼™ä¼´ï¼Ÿ"

        print(f"\né—®é¢˜: {question}")
        print("å›ç­”:")
        async for chunk in agent.query(question):
            print(chunk)


    asyncio.run(main())
